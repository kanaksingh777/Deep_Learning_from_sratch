{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e8c6280-9467-4021-9911-aa68c6142fdd",
   "metadata": {},
   "source": [
    "# Pipeline flow\n",
    "1.load the dataset\n",
    "2.Data preprocessing\n",
    "3.Training Process\n",
    "    a.create the model\n",
    "    b.forward pass\n",
    "    c.loss calculation \n",
    "    d. backprop\n",
    "    e.parameters update\n",
    "4.model evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "45ddd405-e17f-4a6b-87d6-ce720c15c771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e40c373c-f691-43ab-8e6f-213af8cfdb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['id','Unnamed: 32'],inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aa06efba-4c8b-4f27-b4f5-0e3371bbbcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4a903b09-70f0-4830-877d-d96fb27c7622",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(df.iloc[:,1:],df.iloc[:,0],test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cd170d7a-3867-4360-bbd4-27d16dbd17b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "33a5553d-1ee1-4758-811a-1c0c85a8e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cab4e543-4cde-445b-a8fb-03ad335446b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "069fadd2-af86-42ce-b440-ee200eb57e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy aray to pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cbd8ad22-1633-446c-8901-6d4a77697bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b4d71bfb-a476-402b-8ba3-7f4c1eb68686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_train_tensor= torch.FloatTensor(y_train)\n",
    "y_test_tensor= torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e3ea0d3f-e1fb-401b-87f4-e75ad68cb2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5e05c796-1cf7-449b-b835-208d7968eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's define the Structure of the neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "43e5dd0e-c839-4639-adfa-dc010745013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleNN():\n",
    "    def __init__(self,X):\n",
    "        self.weights = torch.rand(X.shape[1],1,dtype = torch.float32, requires_grad = True)\n",
    "        self.bias = torch.zeros(1,dtype = torch.float32,requires_grad = True)\n",
    "\n",
    "    def forward_pass(self,X):\n",
    "        z = torch.matmul(X,self.weights) +self.bias\n",
    "        y_pred = torch.sigmoid(z)\n",
    "        return y_pred\n",
    "\n",
    "    def loss_function(self,y_pred,y):\n",
    "\n",
    "        epsilon =  1e-7\n",
    "        y_pred = torch.clamp(y_pred,epsilon, 1-epsilon)\n",
    "\n",
    "        loss = -(y_train_tensor * torch.log(y_pred) + (1-y_train_tensor) * torch.log(1-y_pred)).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9f6f8166-ba8a-4362-add8-f42766f051de",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_r = 0.1\n",
    "epochs = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "888315e0-2d66-4dac-bf04-f3fa1d52e9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :1 ,Loss = 3.7045276165008545\n",
      "epoch :2 ,Loss = 1.5610004663467407\n",
      "epoch :3 ,Loss = 1.364208698272705\n",
      "epoch :4 ,Loss = 0.7257760763168335\n",
      "epoch :5 ,Loss = 0.8289128541946411\n",
      "epoch :6 ,Loss = 0.7319345474243164\n",
      "epoch :7 ,Loss = 0.8289925456047058\n",
      "epoch :8 ,Loss = 0.7629913091659546\n",
      "epoch :9 ,Loss = 0.8239476680755615\n",
      "epoch :10 ,Loss = 0.7948721647262573\n",
      "epoch :11 ,Loss = 0.8262375593185425\n",
      "epoch :12 ,Loss = 0.8194279074668884\n",
      "epoch :13 ,Loss = 0.8349423408508301\n",
      "epoch :14 ,Loss = 0.8371556401252747\n",
      "epoch :15 ,Loss = 0.8460652232170105\n",
      "epoch :16 ,Loss = 0.8509200811386108\n",
      "epoch :17 ,Loss = 0.8573818206787109\n",
      "epoch :18 ,Loss = 0.8626477122306824\n",
      "epoch :19 ,Loss = 0.8681449294090271\n",
      "epoch :20 ,Loss = 0.8732345104217529\n",
      "epoch :21 ,Loss = 0.8782532215118408\n",
      "epoch :22 ,Loss = 0.8830790519714355\n",
      "epoch :23 ,Loss = 0.8877942562103271\n",
      "epoch :24 ,Loss = 0.8923860192298889\n",
      "epoch :25 ,Loss = 0.8968799710273743\n"
     ]
    }
   ],
   "source": [
    "#training_pipeline\n",
    "model = MySimpleNN(X_train_tensor)\n",
    "\n",
    "for epochs in range(epochs):\n",
    "\n",
    "    #forward_pass \n",
    "    y_pred = model.forward_pass(X_train_tensor)\n",
    "\n",
    "    #calculate loss \n",
    "\n",
    "    loss = model.loss_function(y_pred,y_train_tensor)\n",
    "    print(f'epoch :{epochs+1} ,Loss = {loss.item()}')\n",
    "\n",
    "    #backward pass \n",
    "    loss.backward()\n",
    "    # calculates all the derivates \n",
    "\n",
    "    #parameters update \n",
    "    with torch.no_grad(): # dont track the gradients \n",
    "        \n",
    "        \n",
    "        model.weights -= l_r + model.weights.grad\n",
    "        model.bias  -= l_r + model.bias.grad\n",
    "    model.weights.grad.zero_()\n",
    "    model.bias.grad.zero_()\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "72feae68-391f-45de-8656-92ed5de35b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.6606e-01],\n",
      "        [-2.6129e-01],\n",
      "        [-2.9218e-01],\n",
      "        [-6.7946e-01],\n",
      "        [ 6.7016e-02],\n",
      "        [ 2.2291e-01],\n",
      "        [ 5.5125e-01],\n",
      "        [ 1.6697e-01],\n",
      "        [ 1.0066e-01],\n",
      "        [-5.4003e-01],\n",
      "        [-1.6782e-01],\n",
      "        [-4.1338e-01],\n",
      "        [ 3.3537e-01],\n",
      "        [-2.7113e-01],\n",
      "        [-2.7493e-01],\n",
      "        [-2.9325e-04],\n",
      "        [-2.7625e-01],\n",
      "        [-7.7209e-02],\n",
      "        [-4.2299e-01],\n",
      "        [-9.2377e-02],\n",
      "        [ 1.4471e-01],\n",
      "        [ 5.4814e-02],\n",
      "        [-1.0732e-01],\n",
      "        [-8.6288e-02],\n",
      "        [-3.3270e-01],\n",
      "        [ 2.1299e-01],\n",
      "        [ 7.1319e-02],\n",
      "        [ 2.7909e-01],\n",
      "        [-4.6272e-01],\n",
      "        [-5.7062e-01]], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.2800], requires_grad=True)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.weights)\n",
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cd1ee25c-edc1-4381-8282-af8afe3f5c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVAluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3733617b-b024-412c-9ca5-ebe4b9d44559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :0.669282853603363\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model.forward_pass(X_test_tensor)\n",
    "\n",
    "    y_pred = (y_pred > 0.7).float()\n",
    "\n",
    "    accuracy = (y_pred == y_test_tensor).float().mean()\n",
    "print(f'Accuracy :{accuracy.item()}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5ef70903-915b-433d-9dd9-1cf31fec33d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now creating this using pytorch NN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3aefea3c-c72e-4590-8b5c-6910986634a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inherit from the parent class \n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self,num_features):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_features,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,features):\n",
    "        out = self.fc1(features)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bee2ee56-4256-4e53-878a-031e4aab0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.rand(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5df642f4-6c97-4d72-b1cc-bf7dc781e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eceaa479-0d3a-405c-aa29-2ebfbdb8e568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7513],\n",
       "        [0.7497],\n",
       "        [0.7110],\n",
       "        [0.6984],\n",
       "        [0.6836],\n",
       "        [0.6519],\n",
       "        [0.7157],\n",
       "        [0.6553],\n",
       "        [0.7589],\n",
       "        [0.6879]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6da16e61-720d-4c6b-a002-be9d6c1dc7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3032,  0.0862, -0.0414,  0.4354,  0.3606]], requires_grad=True)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "189a6c98-c1ce-45dc-b53b-0a3564e64ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_2(nn.Module):\n",
    "    def __init__(self,X):\n",
    "        super().__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(X.shape[1],1),\n",
    "            nn.Sigmoid(),\n",
    "            \n",
    "        )\n",
    "    def forward(self,X):\n",
    "        #x = self.flatten(X)\n",
    "        logits = self.network(X)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eff816-a4c7-4a1c-ae1b-2cd6a9fa4586",
   "metadata": {},
   "source": [
    "mo = model_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c45ab6db-7801-4101-8613-d9ef91551dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = model_2(X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "05c750f5-b1ab-4ab5-9d2f-2b3778387cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4057],\n",
       "        [0.4489],\n",
       "        [0.4885],\n",
       "        [0.3209],\n",
       "        [0.8495],\n",
       "        [0.3173],\n",
       "        [0.3127],\n",
       "        [0.3592],\n",
       "        [0.2745],\n",
       "        [0.9476],\n",
       "        [0.4287],\n",
       "        [0.3477],\n",
       "        [0.3101],\n",
       "        [0.2705],\n",
       "        [0.5278],\n",
       "        [0.2736],\n",
       "        [0.4960],\n",
       "        [0.7700],\n",
       "        [0.3713],\n",
       "        [0.3564],\n",
       "        [0.3151],\n",
       "        [0.3073],\n",
       "        [0.8716],\n",
       "        [0.4463],\n",
       "        [0.7459],\n",
       "        [0.6756],\n",
       "        [0.4177],\n",
       "        [0.4145],\n",
       "        [0.3813],\n",
       "        [0.6445],\n",
       "        [0.1717],\n",
       "        [0.4091],\n",
       "        [0.3116],\n",
       "        [0.3567],\n",
       "        [0.5464],\n",
       "        [0.3527],\n",
       "        [0.3415],\n",
       "        [0.6149],\n",
       "        [0.2167],\n",
       "        [0.3517],\n",
       "        [0.3273],\n",
       "        [0.3430],\n",
       "        [0.6568],\n",
       "        [0.2993],\n",
       "        [0.3552],\n",
       "        [0.3116],\n",
       "        [0.5189],\n",
       "        [0.4599],\n",
       "        [0.9562],\n",
       "        [0.2321],\n",
       "        [0.5905],\n",
       "        [0.2228],\n",
       "        [0.5932],\n",
       "        [0.2787],\n",
       "        [0.3892],\n",
       "        [0.6195],\n",
       "        [0.6571],\n",
       "        [0.2579],\n",
       "        [0.5537],\n",
       "        [0.3949],\n",
       "        [0.9240],\n",
       "        [0.2096],\n",
       "        [0.6492],\n",
       "        [0.3446],\n",
       "        [0.4337],\n",
       "        [0.3639],\n",
       "        [0.2958],\n",
       "        [0.3696],\n",
       "        [0.7646],\n",
       "        [0.3416],\n",
       "        [0.7359],\n",
       "        [0.3749],\n",
       "        [0.4170],\n",
       "        [0.9510],\n",
       "        [0.2725],\n",
       "        [0.2198],\n",
       "        [0.3640],\n",
       "        [0.4940],\n",
       "        [0.2095],\n",
       "        [0.7335],\n",
       "        [0.5011],\n",
       "        [0.4792],\n",
       "        [0.4864],\n",
       "        [0.3562],\n",
       "        [0.4179],\n",
       "        [0.8192],\n",
       "        [0.2443],\n",
       "        [0.6249],\n",
       "        [0.3598],\n",
       "        [0.3056],\n",
       "        [0.6664],\n",
       "        [0.4253],\n",
       "        [0.5799],\n",
       "        [0.3034],\n",
       "        [0.7556],\n",
       "        [0.3080],\n",
       "        [0.3175],\n",
       "        [0.6293],\n",
       "        [0.2222],\n",
       "        [0.3359],\n",
       "        [0.3659],\n",
       "        [0.1547],\n",
       "        [0.4917],\n",
       "        [0.4515],\n",
       "        [0.2874],\n",
       "        [0.8682],\n",
       "        [0.3097],\n",
       "        [0.5349],\n",
       "        [0.4038],\n",
       "        [0.2977],\n",
       "        [0.4279],\n",
       "        [0.8440],\n",
       "        [0.8468],\n",
       "        [0.5295],\n",
       "        [0.6348],\n",
       "        [0.4975],\n",
       "        [0.2515],\n",
       "        [0.4110],\n",
       "        [0.4097],\n",
       "        [0.2240],\n",
       "        [0.5901],\n",
       "        [0.8289],\n",
       "        [0.8113],\n",
       "        [0.4389],\n",
       "        [0.2458],\n",
       "        [0.4604],\n",
       "        [0.5414],\n",
       "        [0.6951],\n",
       "        [0.4115],\n",
       "        [0.4610],\n",
       "        [0.6274],\n",
       "        [0.7607],\n",
       "        [0.5860],\n",
       "        [0.4436],\n",
       "        [0.6882],\n",
       "        [0.5570],\n",
       "        [0.6193],\n",
       "        [0.6407],\n",
       "        [0.6006],\n",
       "        [0.3149],\n",
       "        [0.3755],\n",
       "        [0.5232],\n",
       "        [0.6903],\n",
       "        [0.2971],\n",
       "        [0.3181],\n",
       "        [0.3514],\n",
       "        [0.2458],\n",
       "        [0.4920],\n",
       "        [0.4675],\n",
       "        [0.3836],\n",
       "        [0.3548],\n",
       "        [0.2548],\n",
       "        [0.2183],\n",
       "        [0.3928],\n",
       "        [0.3492],\n",
       "        [0.6653],\n",
       "        [0.4091],\n",
       "        [0.6454],\n",
       "        [0.7386],\n",
       "        [0.3006],\n",
       "        [0.6841],\n",
       "        [0.4003],\n",
       "        [0.2733],\n",
       "        [0.4276],\n",
       "        [0.5053],\n",
       "        [0.4921],\n",
       "        [0.4610],\n",
       "        [0.2677],\n",
       "        [0.3647],\n",
       "        [0.3220],\n",
       "        [0.6463],\n",
       "        [0.2741],\n",
       "        [0.6454],\n",
       "        [0.3706],\n",
       "        [0.4124],\n",
       "        [0.7321],\n",
       "        [0.8771],\n",
       "        [0.7749],\n",
       "        [0.7107],\n",
       "        [0.4329],\n",
       "        [0.7343],\n",
       "        [0.8295],\n",
       "        [0.3716],\n",
       "        [0.6435],\n",
       "        [0.3847],\n",
       "        [0.0832],\n",
       "        [0.5981],\n",
       "        [0.2743],\n",
       "        [0.4585],\n",
       "        [0.7479],\n",
       "        [0.7380],\n",
       "        [0.7581],\n",
       "        [0.1410],\n",
       "        [0.2491],\n",
       "        [0.3723],\n",
       "        [0.3963],\n",
       "        [0.2448],\n",
       "        [0.6152],\n",
       "        [0.5079],\n",
       "        [0.6854],\n",
       "        [0.2691],\n",
       "        [0.3337],\n",
       "        [0.3620],\n",
       "        [0.5424],\n",
       "        [0.6333],\n",
       "        [0.3362],\n",
       "        [0.3234],\n",
       "        [0.6243],\n",
       "        [0.4450],\n",
       "        [0.3403],\n",
       "        [0.4682],\n",
       "        [0.2868],\n",
       "        [0.4565],\n",
       "        [0.6330],\n",
       "        [0.8758],\n",
       "        [0.4273],\n",
       "        [0.6590],\n",
       "        [0.6677],\n",
       "        [0.7797],\n",
       "        [0.6062],\n",
       "        [0.6869],\n",
       "        [0.4871],\n",
       "        [0.4604],\n",
       "        [0.4986],\n",
       "        [0.4731],\n",
       "        [0.4373],\n",
       "        [0.2484],\n",
       "        [0.1707],\n",
       "        [0.5075],\n",
       "        [0.5219],\n",
       "        [0.4473],\n",
       "        [0.8208],\n",
       "        [0.3203],\n",
       "        [0.3048],\n",
       "        [0.2698],\n",
       "        [0.7919],\n",
       "        [0.4586],\n",
       "        [0.6693],\n",
       "        [0.3130],\n",
       "        [0.2583],\n",
       "        [0.6621],\n",
       "        [0.2528],\n",
       "        [0.3050],\n",
       "        [0.2269],\n",
       "        [0.9531],\n",
       "        [0.1646],\n",
       "        [0.5921],\n",
       "        [0.3994],\n",
       "        [0.6233],\n",
       "        [0.5201],\n",
       "        [0.2926],\n",
       "        [0.3579],\n",
       "        [0.3572],\n",
       "        [0.7122],\n",
       "        [0.1165],\n",
       "        [0.4548],\n",
       "        [0.2687],\n",
       "        [0.3142],\n",
       "        [0.8091],\n",
       "        [0.5200],\n",
       "        [0.5485],\n",
       "        [0.5861],\n",
       "        [0.2245],\n",
       "        [0.2809],\n",
       "        [0.6432],\n",
       "        [0.6845],\n",
       "        [0.5318],\n",
       "        [0.4261],\n",
       "        [0.3779],\n",
       "        [0.3449],\n",
       "        [0.6246],\n",
       "        [0.7927],\n",
       "        [0.3120],\n",
       "        [0.9279],\n",
       "        [0.5805],\n",
       "        [0.3542],\n",
       "        [0.4254],\n",
       "        [0.3328],\n",
       "        [0.4767],\n",
       "        [0.2758],\n",
       "        [0.2995],\n",
       "        [0.3820],\n",
       "        [0.5735],\n",
       "        [0.7465],\n",
       "        [0.2844],\n",
       "        [0.2309],\n",
       "        [0.2687],\n",
       "        [0.4507],\n",
       "        [0.2850],\n",
       "        [0.4968],\n",
       "        [0.6641],\n",
       "        [0.7698],\n",
       "        [0.6143],\n",
       "        [0.2954],\n",
       "        [0.2717],\n",
       "        [0.3481],\n",
       "        [0.6393],\n",
       "        [0.5075],\n",
       "        [0.2806],\n",
       "        [0.6076],\n",
       "        [0.5621],\n",
       "        [0.4008],\n",
       "        [0.2876],\n",
       "        [0.4398],\n",
       "        [0.2500],\n",
       "        [0.2588],\n",
       "        [0.4740],\n",
       "        [0.4005],\n",
       "        [0.8177],\n",
       "        [0.6407],\n",
       "        [0.2971],\n",
       "        [0.2715],\n",
       "        [0.6038],\n",
       "        [0.4237],\n",
       "        [0.6224],\n",
       "        [0.6798],\n",
       "        [0.1761],\n",
       "        [0.7576],\n",
       "        [0.3206],\n",
       "        [0.4740],\n",
       "        [0.5426],\n",
       "        [0.6075],\n",
       "        [0.2550],\n",
       "        [0.5923],\n",
       "        [0.4453],\n",
       "        [0.4118],\n",
       "        [0.2515],\n",
       "        [0.3598],\n",
       "        [0.2565],\n",
       "        [0.3576],\n",
       "        [0.2257],\n",
       "        [0.2834],\n",
       "        [0.2483],\n",
       "        [0.5164],\n",
       "        [0.4098],\n",
       "        [0.3776],\n",
       "        [0.3880],\n",
       "        [0.4401],\n",
       "        [0.5988],\n",
       "        [0.3104],\n",
       "        [0.2835],\n",
       "        [0.5491],\n",
       "        [0.2978],\n",
       "        [0.5008],\n",
       "        [0.3269],\n",
       "        [0.5317],\n",
       "        [0.7794],\n",
       "        [0.8259],\n",
       "        [0.4916],\n",
       "        [0.3036],\n",
       "        [0.3183],\n",
       "        [0.2956],\n",
       "        [0.2765],\n",
       "        [0.3004],\n",
       "        [0.5509],\n",
       "        [0.3853],\n",
       "        [0.6845],\n",
       "        [0.5748],\n",
       "        [0.2534],\n",
       "        [0.2479],\n",
       "        [0.2934],\n",
       "        [0.5622],\n",
       "        [0.4208],\n",
       "        [0.2823],\n",
       "        [0.2903],\n",
       "        [0.4708],\n",
       "        [0.3292],\n",
       "        [0.7664],\n",
       "        [0.4886],\n",
       "        [0.6052],\n",
       "        [0.3355],\n",
       "        [0.5398],\n",
       "        [0.3322],\n",
       "        [0.5472],\n",
       "        [0.3576],\n",
       "        [0.5618],\n",
       "        [0.2007],\n",
       "        [0.3319],\n",
       "        [0.2472],\n",
       "        [0.4952],\n",
       "        [0.6676],\n",
       "        [0.5273],\n",
       "        [0.2329],\n",
       "        [0.6336],\n",
       "        [0.5286],\n",
       "        [0.4442],\n",
       "        [0.8154],\n",
       "        [0.2223],\n",
       "        [0.2327],\n",
       "        [0.4399],\n",
       "        [0.4898],\n",
       "        [0.7950],\n",
       "        [0.5508],\n",
       "        [0.3704],\n",
       "        [0.2982],\n",
       "        [0.8078],\n",
       "        [0.6512],\n",
       "        [0.4071],\n",
       "        [0.4686],\n",
       "        [0.6395],\n",
       "        [0.6213],\n",
       "        [0.7759],\n",
       "        [0.3221],\n",
       "        [0.3991],\n",
       "        [0.6881],\n",
       "        [0.7047],\n",
       "        [0.2548],\n",
       "        [0.7015],\n",
       "        [0.2478],\n",
       "        [0.3276],\n",
       "        [0.7109],\n",
       "        [0.7864],\n",
       "        [0.3160],\n",
       "        [0.3312],\n",
       "        [0.7981],\n",
       "        [0.3363],\n",
       "        [0.3007],\n",
       "        [0.2703],\n",
       "        [0.7708],\n",
       "        [0.4062],\n",
       "        [0.6180],\n",
       "        [0.3276],\n",
       "        [0.5189],\n",
       "        [0.3377],\n",
       "        [0.6596],\n",
       "        [0.3014],\n",
       "        [0.3028],\n",
       "        [0.2646],\n",
       "        [0.5010],\n",
       "        [0.4465],\n",
       "        [0.7199],\n",
       "        [0.4682],\n",
       "        [0.3406],\n",
       "        [0.7330],\n",
       "        [0.2941],\n",
       "        [0.5422],\n",
       "        [0.6026],\n",
       "        [0.3355],\n",
       "        [0.2858],\n",
       "        [0.3223],\n",
       "        [0.4499],\n",
       "        [0.4042],\n",
       "        [0.2880],\n",
       "        [0.3296],\n",
       "        [0.3788],\n",
       "        [0.4146],\n",
       "        [0.5462],\n",
       "        [0.5322],\n",
       "        [0.4051],\n",
       "        [0.2931],\n",
       "        [0.6854],\n",
       "        [0.3140],\n",
       "        [0.2682],\n",
       "        [0.3388],\n",
       "        [0.3248]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.forward(X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f461db-2ecc-4f19-9d28-16e96393572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "what"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
